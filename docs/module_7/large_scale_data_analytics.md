# Large-scale data analytics

Large-scale data analytics solutions combine conventional **data warehousing** used to support business intelligence (BI) with **data lakehouse techniques** that are used to integrate data from files and external sources. 

A conventional data warehousing solution typically involves copying data from transactional data stores into a relational database with a schema that's optimized for querying and building multidimensional models. 

Data lakehouse solutions on the other hand, are used with large volumes of data in multiple formats, which is batch loaded or captured in real-time streams and stored in a data lake from which distributed processing engines like Apache Spark are used to process it.